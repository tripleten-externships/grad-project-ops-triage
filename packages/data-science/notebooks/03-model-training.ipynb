{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Objective\n",
    "Train machine learning models to predict:\n",
    "1. Request category\n",
    "2. Request priority\n",
    "\n",
    "## Approach\n",
    "- Start with simple baselines (Logistic Regression, Naive Bayes)\n",
    "- Try ensemble methods (Random Forest, XGBoost)\n",
    "- Tune hyperparameters\n",
    "- Save best models for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels from feature engineering\n",
    "data_dir = Path('../data/processed')\n",
    "\n",
    "X = scipy.sparse.load_npz(data_dir / 'X_tfidf.npz')\n",
    "y_category = np.load(data_dir / 'y_category.npy')\n",
    "y_priority = np.load(data_dir / 'y_priority.npy')\n",
    "\n",
    "# Load encoders to decode labels later\n",
    "with open(data_dir / 'category_encoder.pkl', 'rb') as f:\n",
    "    category_encoder = pickle.load(f)\n",
    "with open(data_dir / 'priority_encoder.pkl', 'rb') as f:\n",
    "    priority_encoder = pickle.load(f)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Category labels shape: {y_category.shape}\")\n",
    "print(f\"Priority labels shape: {y_priority.shape}\")\n",
    "print(f\"\\nCategory classes: {category_encoder.classes_}\")\n",
    "print(f\"Priority classes: {priority_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% test)\n",
    "# TODO: Adjust test_size based on dataset size\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, X_test, y_cat_train, y_cat_test, y_pri_train, y_pri_test = train_test_split(\n",
    "    X, y_category, y_priority, test_size=0.2, random_state=RANDOM_STATE, stratify=y_category\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Category Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_cat = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "lr_cat.fit(X_train, y_cat_train)\n",
    "\n",
    "# Predictions\n",
    "y_cat_pred_lr = lr_cat.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression - Category Prediction\")\n",
    "print(f\"Accuracy: {accuracy_score(y_cat_test, y_cat_pred_lr):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_cat_test, y_cat_pred_lr, target_names=category_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try Multinomial Naive Bayes\n",
    "nb_cat = MultinomialNB()\n",
    "nb_cat.fit(X_train, y_cat_train)\n",
    "\n",
    "y_cat_pred_nb = nb_cat.predict(X_test)\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_score(y_cat_test, y_cat_pred_nb):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with Random Forest or XGBoost\n",
    "# Note: Random Forest on sparse data can be slow\n",
    "# rf_cat = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "# rf_cat.fit(X_train, y_cat_train)\n",
    "# y_cat_pred_rf = rf_cat.predict(X_test)\n",
    "# print(f\"Random Forest Accuracy: {accuracy_score(y_cat_test, y_cat_pred_rf):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune hyperparameters if baseline performance is not sufficient\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'solver': ['lbfgs', 'saga']\n",
    "# }\n",
    "# grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_cat_train)\n",
    "# print(f\"Best params: {grid_search.best_params_}\")\n",
    "# print(f\"Best CV score: {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Priority Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression for priority\n",
    "lr_pri = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "lr_pri.fit(X_train, y_pri_train)\n",
    "\n",
    "# Predictions\n",
    "y_pri_pred_lr = lr_pri.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression - Priority Prediction\")\n",
    "print(f\"Accuracy: {accuracy_score(y_pri_test, y_pri_pred_lr):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_pri_test, y_pri_pred_lr, target_names=priority_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Selection\n",
    "\n",
    "Based on performance, choose the best model for each task:\n",
    "\n",
    "TODO: Fill in after experimentation\n",
    "- **Category Model**: <!-- Logistic Regression / Naive Bayes / Random Forest -->\n",
    "- **Priority Model**: <!-- Logistic Regression / etc. -->\n",
    "\n",
    "**Rationale**: <!-- Higher accuracy, better F1-score, faster inference, etc. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save best models (using Logistic Regression for now)\n",
    "with open(models_dir / 'category_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_cat, f)\n",
    "    \n",
    "with open(models_dir / 'priority_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_pri, f)\n",
    "\n",
    "print(f\"Models saved to {models_dir}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'category_model': 'LogisticRegression',\n",
    "    'category_accuracy': float(accuracy_score(y_cat_test, y_cat_pred_lr)),\n",
    "    'priority_model': 'LogisticRegression',\n",
    "    'priority_accuracy': float(accuracy_score(y_pri_test, y_pri_pred_lr)),\n",
    "    'trained_date': pd.Timestamp.now().isoformat(),\n",
    "    'n_train_samples': X_train.shape[0],\n",
    "    'n_test_samples': X_test.shape[0]\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(models_dir / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\nModel Metadata:\")\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confidence Scores\n",
    "\n",
    "Extract probability scores for predictions (used for confidence thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions\n",
    "y_cat_proba = lr_cat.predict_proba(X_test)\n",
    "y_pri_proba = lr_pri.predict_proba(X_test)\n",
    "\n",
    "# Max probability (confidence)\n",
    "cat_confidence = y_cat_proba.max(axis=1)\n",
    "pri_confidence = y_pri_proba.max(axis=1)\n",
    "\n",
    "print(f\"Category confidence - Mean: {cat_confidence.mean():.3f}, Min: {cat_confidence.min():.3f}, Max: {cat_confidence.max():.3f}\")\n",
    "print(f\"Priority confidence - Mean: {pri_confidence.mean():.3f}, Min: {pri_confidence.min():.3f}, Max: {pri_confidence.max():.3f}\")\n",
    "\n",
    "# Plot confidence distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(cat_confidence, bins=30, edgecolor='black')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Category Prediction Confidence')\n",
    "plt.axvline(0.6, color='red', linestyle='--', label='Threshold=0.6')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(pri_confidence, bins=30, edgecolor='black')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Priority Prediction Confidence')\n",
    "plt.axvline(0.6, color='red', linestyle='--', label='Threshold=0.6')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "1. Proceed to `04-model-evaluation.ipynb` for detailed evaluation\n",
    "2. Analyze confusion matrices, per-class performance\n",
    "3. Identify error patterns\n",
    "4. Create model card in `docs/MODEL-CARD.md`\n",
    "5. Build prediction API in `api/app.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**References**:\n",
    "- Output Schema: `contracts/integration-points/ds-model-output.schema.json`\n",
    "- Priority Definitions: `contracts/data-models/priority-definitions.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
