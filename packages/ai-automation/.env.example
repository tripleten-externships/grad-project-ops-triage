# AI Automation Environment Variables

# API Keys (choose one or more)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
# GOOGLE_API_KEY=...  # For Gemini

# Preferred LLM provider
LLM_PROVIDER=openai  # Options: openai, anthropic, google

# Model selection
OPENAI_MODEL=gpt-3.5-turbo  # Options: gpt-3.5-turbo, gpt-4, gpt-4-turbo
ANTHROPIC_MODEL=claude-3-sonnet-20240229  # Options: claude-3-opus, claude-3-sonnet, claude-3-haiku

# Server Configuration
PORT=8002
HOST=0.0.0.0

# Backend Integration
BACKEND_URL=http://localhost:3000
BACKEND_API_KEY=your-api-key-here

# Confidence Thresholds
CATEGORY_CONFIDENCE_THRESHOLD=0.6
PRIORITY_CONFIDENCE_THRESHOLD=0.6

# Fallback Strategy
# If LLM fails, try DS model?
USE_DS_MODEL_FALLBACK=true
DS_MODEL_API_URL=http://localhost:8001

# Guardrails
MAX_DESCRIPTION_LENGTH=5000
MIN_DESCRIPTION_LENGTH=10
ENABLE_PII_DETECTION=true
ENABLE_SENSITIVE_CONTENT_FLAGGING=true

# Logging
LOG_LEVEL=info  # Options: error, warn, info, debug
LOG_TO_FILE=true
LOG_FILE_PATH=./logs/ai-automation.log

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=100

# Cost Tracking
ENABLE_COST_TRACKING=true

# Development/Testing
NODE_ENV=development

# TODO: Replace with actual API keys before deployment
# TODO: Never commit real API keys to git
# TODO: Use secrets manager in production
