# Judging Criteria & Evaluation Rubric

This document outlines how each discipline's deliverables will be evaluated. Use this as a checklist to ensure your work meets expectations.

## ğŸ“Š Overall Grading Structure

Each discipline is evaluated on:
- **Required Deliverables** (60%): Must-have items
- **Quality Criteria** (30%): How well it's done
- **Stretch Goals** (10%): Optional advanced features

**Total Project Score**: Average of completed discipline scores

---

## ğŸ¨ UX/UI Design

**Overall Weight**: 14% of total project

### Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **User Research** | 10 | [`ux-design/research/`](../packages/ux-design/research/) | âœ… At least 2 personas defined<br>âœ… Problem framing documented<br>âœ… Success metrics identified |
| **User Flows** | 15 | [`ux-design/user-flows/`](../packages/ux-design/user-flows/) | âœ… All 3 core flows (Submit, Triage, Insights)<br>âœ… Mermaid diagrams render correctly<br>âœ… Decision points clearly marked |
| **Design System** | 10 | [`ux-design/design-system/`](../packages/ux-design/design-system/) | âœ… Color palette defined<br>âœ… Typography scale<br>âœ… Component specifications<br>âœ… Design tokens (JSON) |
| **High-Fidelity Prototype** | 15 | [`ux-design/prototypes/`](../packages/ux-design/prototypes/) | âœ… Figma link provided<br>âœ… All 3 core screens designed<br>âœ… Interactive prototype<br>âœ… Mobile & desktop views |
| **Accessibility Guidelines** | 5 | [`ux-design/accessibility/`](../packages/ux-design/accessibility/) | âœ… WCAG 2.1 AA compliance plan<br>âœ… Color contrast checked<br>âœ… Keyboard navigation considered |
| **Developer Handoff** | 5 | [`ux-design/handoff/`](../packages/ux-design/handoff/) | âœ… Component specs documented<br>âœ… Measurements provided<br>âœ… Asset export guide |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Design Quality** | 10 | Professional visual design, consistent styling, good use of whitespace |
| **Usability** | 10 | Intuitive flows, clear CTAs, minimal cognitive load, error prevention |
| **Documentation** | 5 | Clear explanations, rationale for decisions, easy to follow |
| **Accessibility** | 5 | Semantic HTML considerations, ARIA labels planned, inclusive design |

### Stretch Goals (10 points)

- [ ] **Interaction Design** (3pts): Micro-interactions, animations, loading states specified
- [ ] **Advanced Accessibility** (3pts): Screen reader testing, WCAG AAA considerations
- [ ] **Usability Testing** (4pts): Prototype tested with 3+ users, findings documented

**Total**: 100 points

---

## ğŸ’» Software Engineering

**Overall Weight**: 28% of total project (14% Frontend + 14% Backend)

### Frontend - Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **Intake Page** | 12 | [`frontend/src/pages/intake/`](../packages/frontend/src/pages/intake/) | âœ… Form with all required fields<br>âœ… Validation<br>âœ… File upload (optional)<br>âœ… Success feedback |
| **Triage Queue Page** | 15 | [`frontend/src/pages/triage/`](../packages/frontend/src/pages/triage/) | âœ… List of requests<br>âœ… Filtering & sorting<br>âœ… Status updates<br>âœ… Assignment functionality |
| **Request Detail Page** | 10 | [`frontend/src/pages/detail/`](../packages/frontend/src/pages/detail/) | âœ… Full request display<br>âœ… Edit capability<br>âœ… Status history<br>âœ… AI suggestions shown |
| **Insights Dashboard** | 8 | [`frontend/src/pages/insights/`](../packages/frontend/src/pages/insights/) | âœ… Key metrics displayed<br>âœ… Charts/visualizations<br>âœ… Data from backend API |
| **API Integration** | 10 | [`frontend/src/services/api.ts`](../packages/frontend/src/services/api.ts) | âœ… All CRUD operations<br>âœ… Error handling<br>âœ… TypeScript types<br>âœ… Matches API contract |
| **Deployment** | 5 | Build works | âœ… `pnpm build` succeeds<br>âœ… No console errors<br>âœ… Environment config |

### Backend - Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **Request API** | 15 | [`backend/src/routes/requests.routes.ts`](../packages/backend/src/routes/requests.routes.ts) | âœ… All CRUD endpoints<br>âœ… Filtering & pagination<br>âœ… Matches OpenAPI contract |
| **Triage API** | 10 | [`backend/src/routes/triage.routes.ts`](../packages/backend/src/routes/triage.routes.ts) | âœ… Manual triage endpoint<br>âœ… Calls DS API<br>âœ… Updates request |
| **Analytics API** | 10 | [`backend/src/routes/analytics.routes.ts`](../packages/backend/src/routes/analytics.routes.ts) | âœ… Summary metrics<br>âœ… SLA calculations<br>âœ… Category breakdown |
| **Database Models** | 10 | [`backend/src/models/`](../packages/backend/src/models/) | âœ… Request model matches schema<br>âœ… User model<br>âœ… Proper validation<br>âœ… Indexes |
| **Webhook Service** | 10 | [`backend/src/services/webhook.service.ts`](../packages/backend/src/services/webhook.service.ts) | âœ… Emit events on changes<br>âœ… Retry logic<br>âœ… Matches event contract |
| **Seed Data** | 5 | [`backend/src/utils/seed-database.ts`](../packages/backend/src/utils/seed-database.ts) | âœ… Script works<br>âœ… Uses mock data<br>âœ… Idempotent |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Code Quality** | 8 | Clean code, proper separation of concerns, DRY principle, consistent style |
| **TypeScript Usage** | 6 | Proper typing, no `any`, interfaces for contracts |
| **Error Handling** | 6 | Try-catch blocks, meaningful error messages, HTTP status codes |
| **Testing** | 5 | At least unit tests for critical functions (optional but recommended) |
| **Documentation** | 5 | API docs, inline comments for complex logic, README completeness |

### Stretch Goals (10 points)

- [ ] **Authentication** (3pts): JWT-based auth, protected routes
- [ ] **Real-time Updates** (3pts): WebSockets for live queue updates
- [ ] **File Upload** (2pts): Handle attachment uploads/storage
- [ ] **Comprehensive Testing** (2pts): >70% code coverage

**Total**: 200 points (100 Frontend + 100 Backend)

---

## ğŸ“Š Data Science

**Overall Weight**: 14% of total project

### Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **Exploratory Data Analysis** | 10 | [`data-science/notebooks/01-eda.ipynb`](../packages/data-science/notebooks/01-eda.ipynb) | âœ… Data loaded and explored<br>âœ… Visualizations<br>âœ… Insights documented<br>âœ… Missing data handled |
| **Feature Engineering** | 10 | [`data-science/notebooks/02-feature-engineering.ipynb`](../packages/data-science/notebooks/02-feature-engineering.ipynb) | âœ… Text features (TF-IDF, embeddings)<br>âœ… Feature selection<br>âœ… Preprocessing pipeline |
| **Model Training** | 15 | [`data-science/notebooks/03-model-training.ipynb`](../packages/data-science/notebooks/03-model-training.ipynb) | âœ… Category classification model<br>âœ… Priority classification model<br>âœ… Hyperparameter tuning<br>âœ… Models saved |
| **Model Evaluation** | 10 | [`data-science/notebooks/04-model-evaluation.ipynb`](../packages/data-science/notebooks/04-model-evaluation.ipynb) | âœ… Accuracy, precision, recall, F1<br>âœ… Confusion matrices<br>âœ… Error analysis<br>âœ… Model comparison |
| **Model API** | 10 | [`data-science/api/app.py`](../packages/data-science/api/app.py) | âœ… FastAPI endpoint `/predict`<br>âœ… Loads trained models<br>âœ… Returns predictions matching contract<br>âœ… Error handling |
| **Model Card** | 5 | [`data-science/docs/MODEL-CARD.md`](../packages/data-science/docs/MODEL-CARD.md) | âœ… Model description<br>âœ… Performance metrics<br>âœ… Limitations documented<br>âœ… Intended use |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Model Performance** | 12 | Category >80% accuracy, Priority >70% accuracy |
| **Code Quality** | 6 | Clean notebooks, reusable functions, proper imports |
| **Documentation** | 6 | Markdown cells explain steps, visualizations labeled, findings clear |
| **Reproducibility** | 6 | Requirements.txt complete, random seeds set, data paths configurable |

### Stretch Goals (10 points)

- [ ] **Advanced Models** (3pts): Try BERT, transformers, or ensemble methods
- [ ] **Confidence Scores** (2pts): Provide calibrated confidence with predictions
- [ ] **Agent Recommendation** (3pts): Suggest best agent based on expertise/availability
- [ ] **Model Monitoring** (2pts): Track prediction accuracy over time

**Total**: 100 points

---

## ğŸ“ˆ Business Intelligence & Analytics

**Overall Weight**: 14% of total project

### Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **Dashboard** | 25 | [`bia/dashboards/`](../packages/bia/dashboards/) | âœ… Working dashboard in chosen tool<br>âœ… At least 5 visualizations<br>âœ… Filters/slicers functional<br>âœ… Professional design |
| **Metric Definitions** | 10 | [`bia/docs/METRIC-DEFINITIONS.md`](../packages/bia/docs/METRIC-DEFINITIONS.md) | âœ… All metrics defined<br>âœ… Calculation formulas<br>âœ… Business context |
| **SQL Queries** | 10 | [`bia/queries/`](../packages/bia/queries/) | âœ… Volume metrics query<br>âœ… SLA metrics query<br>âœ… Category analysis query<br>âœ… Queries work on seed data |
| **Insights Memo** | 10 | [`bia/docs/INSIGHTS-MEMO.md`](../packages/bia/docs/INSIGHTS-MEMO.md) | âœ… 3+ actionable insights<br>âœ… Data-driven recommendations<br>âœ… Executive summary |
| **Dashboard Guide** | 5 | [`bia/docs/DASHBOARD-GUIDE.md`](../packages/bia/docs/DASHBOARD-GUIDE.md) | âœ… How to use dashboard<br>âœ… Metric explanations<br>âœ… Setup instructions |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Visual Design** | 8 | Clear charts, good color choices, proper chart types, readable |
| **Insights Quality** | 10 | Actionable, specific, supported by data, valuable to stakeholders |
| **Data Accuracy** | 6 | Calculations correct, metrics match definitions, no errors |
| **Usability** | 6 | Easy to navigate, filters intuitive, purpose clear |

### Stretch Goals (10 points)

- [ ] **Predictive Analytics** (4pts): Forecast future request volume or trends
- [ ] **Advanced Visualizations** (3pts): Heat maps, geo maps, custom visuals
- [ ] **Interactive Features** (3pts): Drill-through, what-if analysis, dynamic filtering

**Total**: 100 points

---

## ğŸ¤– AI Automation

**Overall Weight**: 14% of total project

### Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **Categorization Prompt** | 12 | [`ai-automation/prompts/categorize-request.txt`](../packages/ai-automation/prompts/categorize-request.txt) | âœ… Clear instructions<br>âœ… Examples provided<br>âœ… Output format specified<br>âœ… Achieves >85% accuracy |
| **Priority Assignment Prompt** | 12 | [`ai-automation/prompts/assign-priority.txt`](../packages/ai-automation/prompts/assign-priority.txt) | âœ… References SLA definitions<br>âœ… Examples for each priority<br>âœ… Achieves >80% accuracy |
| **Summarization Prompt** | 8 | [`ai-automation/prompts/summarize-request.txt`](../packages/ai-automation/prompts/summarize-request.txt) | âœ… Produces concise summaries<br>âœ… Maintains key details<br>âœ… Consistent format |
| **Guardrails** | 10 | [`ai-automation/prompts/guardrails.md`](../packages/ai-automation/prompts/guardrails.md) | âœ… Safety checks defined<br>âœ… Validation rules<br>âœ… Fallback strategies documented |
| **Automation Workflow** | 10 | [`ai-automation/workflows/`](../packages/ai-automation/workflows/) | âœ… Workflow documented<br>âœ… Diagram provided<br>âœ… Integration with backend<br>âœ… Works end-to-end |
| **Integration Doc** | 8 | [`ai-automation/docs/INTEGRATION.md`](../packages/ai-automation/docs/INTEGRATION.md) | âœ… Setup instructions<br>âœ… API key configuration<br>âœ… Webhook integration explained |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Prompt Quality** | 10 | Clear, specific, few-shot examples, structured output, good results |
| **Accuracy** | 8 | Predictions align with expected categories/priorities |
| **Guardrails** | 6 | Handles edge cases, validates outputs, falls back gracefully |
| **Documentation** | 6 | Clear explanations, setup steps, troubleshooting guide |

### Stretch Goals (10 points)

- [ ] **Advanced Prompting** (3pts): Chain-of-thought, self-consistency, or other advanced techniques
- [ ] **Multi-step Workflow** (4pts): Complex workflow with conditional logic in n8n/Zapier
- [ ] **Feedback Loop** (3pts): Learn from corrections, adapt prompts based on accuracy

**Total**: 100 points

---

## ğŸ”’ Cyber Security

**Overall Weight**: 14% of total project

### Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **STRIDE Threat Model** | 20 | [`security/threat-model/STRIDE-analysis.md`](../packages/security/threat-model/STRIDE-analysis.md) | âœ… All STRIDE categories covered<br>âœ… 10+ threats identified<br>âœ… Severity ratings<br>âœ… Mitigations proposed |
| **Attack Vectors** | 10 | [`security/threat-model/attack-vectors.md`](../packages/security/threat-model/attack-vectors.md) | âœ… API attack vectors<br>âœ… Frontend vulnerabilities<br>âœ… Data exposure risks documented |
| **Security Policies** | 15 | [`security/policies/`](../packages/security/policies/) | âœ… Authentication policy<br>âœ… Data handling policy<br>âœ… Clear, actionable requirements |
| **OWASP Top 10 Checklist** | 10 | [`security/checklists/owasp-top-10.md`](../packages/security/checklists/owasp-top-10.md) | âœ… All 10 categories addressed<br>âœ… Application-specific checks<br>âœ… Remediation steps |
| **Security Summary** | 5 | [`security/docs/SECURITY-SUMMARY.md`](../packages/security/docs/SECURITY-SUMMARY.md) | âœ… Executive summary<br>âœ… Key findings<br>âœ… Risk prioritization<br>âœ… Recommendations |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Threat Analysis Depth** | 10 | Realistic threats, considers actual system, detailed attack scenarios |
| **Mitigation Practicality** | 8 | Solutions are implementable, specific to this app, cost-effective |
| **Documentation Quality** | 6 | Clear writing, well-organized, actionable for developers |
| **Coverage** | 6 | All components reviewed (frontend, backend, API, data), no major gaps |

### Stretch Goals (10 points)

- [ ] **Code Review** (4pts): Actually review code for vulnerabilities, provide specific findings
- [ ] **Penetration Testing** (4pts): Attempt exploit, document findings
- [ ] **Security Automation** (2pts): Automated security scanning (SAST/DAST)

**Total**: 100 points

---

## ğŸ§ª QA (Quality Assurance)

**Overall Weight**: 14% of total project

### Required Deliverables (60 points)

| Deliverable | Points | Location | Criteria |
|-------------|--------|----------|----------|
| **Test Strategy** | 10 | [`qa/test-strategy/TEST-STRATEGY.md`](../packages/qa/test-strategy/TEST-STRATEGY.md) | âœ… Scope defined<br>âœ… Test levels identified<br>âœ… Entry/exit criteria<br>âœ… Tools specified |
| **Test Cases** | 15 | [`qa/test-cases/`](../packages/qa/test-cases/) | âœ… 15+ test cases<br>âœ… Cover all 3 user stories<br>âœ… Clear steps & expected results<br>âœ… Edge cases included |
| **E2E Tests** | 15 | [`qa/e2e-tests/tests/`](../packages/qa/e2e-tests/tests/) | âœ… Submit request flow automated<br>âœ… Agent triage flow automated<br>âœ… Tests pass<br>âœ… Uses Playwright |
| **API Tests** | 10 | [`qa/api-tests/`](../packages/qa/api-tests/) | âœ… REST client collection OR code-based tests<br>âœ… Cover main endpoints<br>âœ… Positive & negative cases |
| **Test Guide** | 5 | [`qa/docs/TEST-GUIDE.md`](../packages/qa/docs/TEST-GUIDE.md) | âœ… How to run tests<br>âœ… Environment setup<br>âœ… Interpreting results |
| **Bug Reports** | 5 | [`qa/docs/BUG-TEMPLATE.md`](../packages/qa/docs/BUG-TEMPLATE.md) + actual bugs if found | âœ… Template provided<br>âœ… If bugs found, reported properly |

### Quality Criteria (30 points)

| Criterion | Points | What We Look For |
|-----------|--------|------------------|
| **Test Coverage** | 10 | All critical paths tested, edge cases considered, good mix of test types |
| **Test Quality** | 8 | Tests are reliable (not flaky), clear assertions, good test data |
| **Documentation** | 6 | Test cases easy to understand, clear steps, reproducible |
| **Automation** | 6 | E2E tests run successfully, meaningful assertions, good selectors |

### Stretch Goals (10 points)

- [ ] **Visual Regression Testing** (3pts): Screenshot comparison tests
- [ ] **Performance Testing** (3pts): Load testing, response time benchmarks
- [ ] **Accessibility Testing** (2pts): Automated a11y tests with Axe
- [ ] **CI/CD Integration** (2pts): Tests run in GitHub Actions or similar

**Total**: 100 points

---

## ğŸ“‹ Summary Scorecard

| Discipline | Required | Quality | Stretch | Total | Weight |
|------------|----------|---------|---------|-------|--------|
| **UX/UI Design** | 60 | 30 | 10 | 100 | 14% |
| **Frontend Engineering** | 60 | 30 | 10 | 100 | 14% |
| **Backend Engineering** | 60 | 30 | 10 | 100 | 14% |
| **Data Science** | 60 | 30 | 10 | 100 | 14% |
| **BIA** | 60 | 30 | 10 | 100 | 14% |
| **AI Automation** | 60 | 30 | 10 | 100 | 14% |
| **Cyber Security** | 60 | 30 | 10 | 100 | 14% |
| **QA** | 60 | 30 | 10 | 100 | 14% |

**Project Grade** = Weighted average of completed disciplines

---

## âœ… Minimum Passing Criteria

To pass the project:

1. **Required Deliverables**: At least 48/60 points (80%)
2. **Quality**: At least 18/30 points (60%)
3. **Overall**: At least 70/100 points per discipline
4. **Integration**: System must work end-to-end for at least one user story

---

## ğŸŒŸ Excellence Criteria (90+ points)

To achieve excellence:

- All required deliverables complete and high-quality
- Quality criteria consistently met
- At least one stretch goal completed
- Exceptional documentation
- Demonstrates deep understanding
- Goes beyond requirements in meaningful ways

---

## ğŸ” Self-Assessment Checklist

Before submission, check:

- [ ] All required deliverables are in the correct locations
- [ ] Code/files follow naming conventions
- [ ] Documentation is complete and clear
- [ ] Work matches contract specifications
- [ ] Tests pass (if applicable)
- [ ] Integration points work
- [ ] No placeholder/TODO content in deliverables
- [ ] README for your discipline is updated

---

## ğŸ“Š How to Use This Document

**As a Student**:
1. Review criteria for your discipline before starting
2. Use as a checklist while working
3. Self-assess before final submission
4. Aim for required deliverables first, then quality, then stretch

**As an Instructor**:
1. Use as grading rubric
2. Provide specific feedback per criterion
3. Adjust weights if needed for your course
4. Share with students at project start

---

**Remember**: The goal is learning, not just points. Focus on building something meaningful and understanding how it all fits together! ğŸ¯
